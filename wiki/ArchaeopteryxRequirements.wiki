#summary The evolving requirements document of the functional simulator
#labels Phase-Requirements,Archaeopteryx,Simulation

= Vision =

[http://www.gdiamos.net/images/archaeopteryx.jpg]

Enable *fast* simulation of future architectures on modern hardware.  

= Goals =

 * Functionally simulate a many-core processor using GPUs.
 * Constant slowdown factor when simulating a new processor on current generation hardware.
 * Make all components modular, with well defined interfaces, especially with regards to the ISA.
 * ISA and runtime extensions for data distributions and locality.
 * Lightweight and modular instrumentation or trace generation interface for interactions with timing models.

= Requirements =

 * Simulate complete CUDA applications.  As a starting point, simulate the PTX virtual machine (this may need revision).
 * A fast virtual machine IR and byte-code format.  Ideally, this should be loaded, and simulated in parallel.
 * Written completely in CUDA device code.  No host code at all for the simulator engine.

= Component List =
 * An IR and a byte-code format 
 * Processor simulator
  * Kernel Instructions
  * Memory module
  * Core simulator
   * Instruction execution engine
 * Runtime
 * Event Handlers
 * Test framework
  * Unit tests
   * Feature coverage
   * Input parameters
   * Output parameters
  * Test space exploration
  * Random program generation

= Component Design =

This section covers the aforementioned components in more detail.

== IR and Byte-Code ==

The IR will be a set of CUDA classes that represent ISA abstractions, such as instructions or memory allocations.  The byte-code format will provide an efficient mechanism for storing and loading this IR to disk.  This format should allow files to be loaded in a data-parallel fashion that can achieve close to peak performance on the system performing the simulation.

== Processor Simulator ==

The processor simulator is the top level component.  It contains a collection of memory modules, core models, and kernel instructions that are fed to CTAs during the execution of the program. This dispatches work to the various core simulator instances. The physical interconnections between various components is not modeled here, instead all cores are assumed to be connected to each memory module. For now we adopt the convention in current architectures where cores are not directly connected to each other.

=== Kernel Instructions ===

Kernel instructions will be stored in a pre-decoded IR form in the last level shared memory space of the machine performing the simulation.  The instructions for an entire program will be mapped into this memory space, but they should be loaded lazily from a byte-code file, one page at a time.  This will require some tricks to get working correctly with CUDA, but it should ensure that significantly less than the full binary needs to be loaded at a time into the memory of the machine performing the simulation.  Additional work will be needed to design an IR storage format that enables this behavior.

=== Memory Modules ===

Memory modules represent relocatable pages of memory that are available to the currently executing application.  They will be associated with the current process only.  Modules will be associated with an allocation function, which controls their distribution on a system with multiple memory controllers and a multi-level tiled cache.

=== Core Simulator ===

The core simulator is responsible for executing complete CTAs.  It will be given a starting instruction and a set of memory regions that it has access to.  There will also be a set of memory regions that are shared across all CTAs, but are assumed to support more efficient access from this CTA.

Instructions will be loaded lazily.  They should be grouped into pages and only allocated and read from the byte-code file when the first thread executes them.  The Core simulator should cache valid regions of instructions and atomically update a shared data structure containing the loaded instruction pages.

==== Instruction Execution Engine ====

This component is responsible for executing single instructions at a time.  It should maintain per-thread local state (register files, local stack pointers etc.) as well as interfaces to the per-CTA and per-processor shared state (mainly memory). 

It will be used by the Core Simulator to execute individual instructions.  The idea is that the Core Simulator will get the next instruction to execute and call the Execution Engine to execute it.  This will be equivalent to a switch statement over the opcode followed by instruction specific operations (although performance considerations may mandate a different implementation).  

== Runtime ==

The runtime component will be a low level interface that allows the configuration and execution of kernels on the simulator, allowing the simulator to be run as a back-end to a variety of front-ends languages, such as CUDA or OpenCL via [http://code.google.com/p/gpuocelot/ Ocelot].  

Functionality will be provided for the following basic operations:
 * Lazily loading a byte-code file for execution.
 * Allocating and configuring memory.
 * Setup the parameters of the next kernel and perform the launch.
 * Registering simulation event handlers.

No other advanced functions such as concurrent simulation of programs or asynchronous operations will be supported at this level.

== Event Handlers ==

Event handlers are user-defined functions that implement an interface that receives callbacks when pre-defined events occur during simulation.  In the most basic case, event handlers are attached to instruction execution engines, and a callback is triggered after each instruction is executed.  The interface should be designed such that many event handlers can be registered at a time, and many instances of each event handler can be running in parallel, attached to different core simulators, memory modules, or instruction execution engines.

== Test framework ==
=== Unit tests ===
==== Feature coverage ====
==== Input parameters ====
==== Output parameters ====
=== Test space exploration ===
=== Random program generation ===
=== Test Dependencies ===
=== The Test Database ===
=== Distributed Testing ===

= Infrastructure Requirements =

 * Access to GPU workstations or laptops
 * CUDA compiler

= Schedule =